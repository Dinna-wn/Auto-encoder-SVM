# -*- coding: utf-8 -*-
"""tp3_evaluation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11PDXPWiRKXVfljspTRQgmYzt2i8-TZRH
"""

# ==========================================
# ======CHARGEMENT DES LIBRAIRIES===========
# ==========================================

# La libraire responsable du chargement des données dans la mémoire
from keras.preprocessing.image import ImageDataGenerator

# Le Model à compiler
from keras.models import Model

# Le type d'optimisateur utilisé dans notre modèle (RMSprop, adam, sgd, adaboost ...)
# L'optimisateur ajuste les poids de notre modèle par descente du gradient
# Chaque optimisateur a ses propres paramètres
# Note: Il faut tester plusieurs et ajuster les paramètres afin d'avoir les meilleurs résultats

from tensorflow.keras.optimizers import Adam

# Les types des couches utlilisées dans notre modèle
from keras.layers import Conv2D, MaxPooling2D, Input, BatchNormalization, UpSampling2D, Activation, Dropout, Flatten, \
    Dense

# Des outils pour suivre et gérer l'entrainement de notre modèle
from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping

# Configuration du GPU
import tensorflow as tf

# Affichage des graphes
import matplotlib.pyplot as plt

from keras import backend as K
#Import de la librairie Drive
# from google.colab import drive

from keras.models import Sequential
# from tensorflow.keras.layers import Embedding

from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score

from sklearn.preprocessing import StandardScaler


from sklearn.model_selection import cross_val_score

import random
from random import randint

from sklearn.manifold import TSNE
from sklearn.decomposition import PCA

from google.colab import drive
drive.mount('/content/drive')

drive.mount('/content/drive')
file="/content/drive/MyDrive/vache_elephant.zip"

!unzip -q "/content/drive/MyDrive/vache_elephant.zip"

# ==========================================
# ===============GPU SETUP==================
# ==========================================

# Configuration des GPUs et CPUs
config = tf.compat.v1.ConfigProto(device_count={'GPU': 2, 'CPU': 4})
sess = tf.compat.v1.Session(config=config)
tf.compat.v1.keras.backend.set_session(sess);

print("-----------------------------------------------------------\
--------------------------------------------------------")

# **************************************************************************
# INF7370 Apprentissage automatique – Hiver 2022
# Travail pratique 3
# ===========================================================================

#===========================================================================
# Dans ce script, on évalue l'autoencodeur entrainé dans 1_Modele.py sur les données tests.
# On charge le modèle en mémoire puis on charge les images tests en mémoire
# 1) On évalue la qualité des images reconstruites par l'autoencodeur
# 2) On évalue avec une tache de classification la qualité de l'embedding
# 3) On visualise l'embedding en 2 dimensions avec un scatter plot


# ==========================================
# ======CHARGEMENT DES LIBRAIRIES===========
# ==========================================

# La libraire responsable du chargement des données dans la mémoire
from keras.preprocessing.image import ImageDataGenerator

# Affichage des graphes et des images
import matplotlib.pyplot as plt

# La librairie numpy
import numpy as np

# Configuration du GPU
import tensorflow as tf

# Utlilisé pour charger le modèle
from keras.models import load_model
from keras import Model

# Utilisé pour normaliser l'embedding
from sklearn.preprocessing import StandardScaler

from keras import backend as K

# ==========================================
# ==================MODÈLE==================
# ==========================================

# Chargement du modéle (autoencodeur) sauvegardé dans la section 1 via 1_Modele.py
model_path = "/content/drive/MyDrive/Model.hdf5"
autoencoder = load_model(model_path)

# ==========================================
# ================VARIABLES=================
# ==========================================

# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
#                       QUESTIONS
# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
# 1) A ajuster les variables suivantes selon votre problème:
# - mainDataPath
# - number_images
# - number_images_class_x
# - image_scale
# - images_color_mode
# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>


# L'emplacement des images
mainDataPath = "/content/vache_elephant/"

# On évalue le modèle sur les images tests
datapath = mainDataPath + "test"

# Le nombre des images de test à évaluer
number_images = 400 # 400 images
number_images_class_0 = 200 # 200 images pour la classe du chiffre 2
number_images_class_1 = 200 # 200 images pour la classe du chiffre 7

# Les étiquettes (classes) des images
labels = np.array([0] * number_images_class_0 +
                  [1] * number_images_class_1)

# La taille des images
image_scale = 112

# La couleur des images
images_color_mode = "rgb"  # grayscale ou rgb

# ==========================================
# =========CHARGEMENT DES IMAGES============
# ==========================================

# Chargement des images test
data_generator = ImageDataGenerator(rescale=1. / 255)

generator = data_generator.flow_from_directory(
    datapath, # Place des images d'entrainement
    color_mode=images_color_mode, # couleur des images
    target_size=(image_scale, image_scale),# taille des images
    batch_size= number_images, # nombre d'images total à charger en mémoire
    class_mode="binary",
    shuffle=False) # pas besoin de bouleverser les images

# x = generator.next()
(x, y_true) = generator.next()

# ***********************************************
#                  QUESTIONS
# ***********************************************
#
# 2) Reconstruire les images tests en utilisant l'autoencodeur entrainé dans la première étape.
# Pour chacune des classes: Afficher une image originale ainsi que sa reconstruction.
# Afficher le titre de chaque classe au-dessus de l'image
# Note: Les images sont normalisées (entre 0 et 1), alors il faut les multiplier
# par 255 pour récupérer les couleurs des pixels
#
# ***********************************************

decoded_imgs = autoencoder.predict(x)

n = 2
plt.figure(figsize=(10, 4), dpi=150)
random_index_shift = randint(0, len(x) ) 
for i in range(n):
    # display original
    ax = plt.subplot(2, n, i + 1)
    plt.imshow(tf.squeeze(x[random_index_shift]))
    plt.gray()
    if random_index_shift <= len(x)/2 :
       plt.title("originale: Classe Elephant")
    else:    
       plt.title("originale: Classe Vache")


    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # display reconstruction
    ax = plt.subplot(2, n, i + 1 + n)
    plt.imshow(decoded_imgs[random_index_shift])
    plt.gray()
    if random_index_shift <= len(x)/2 :
       plt.title("reconstruite: Classe Elephant")
       random_index_shift = randint(200, len(x) ) 
    else:    
       plt.title("reconstruite: Classe Vache")
       random_index_shift = randint(0, 200 ) 

    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()



# ***********************************************
#                  QUESTIONS
# ***********************************************
#
# 3) Définire un modèle "encoder" qui est formé de la partie encodeur de l'autoencodeur
# Appliquer ce modèle sur les images afin de récupérer l'embedding
# Note: Il est "nécessaire" d'appliquer la fonction (flatten) sur l'embedding
# afin de réduire la représentation de chaque image en un seul vecteur
#
# ***********************************************

# Défintion du modèle
input_layer_index = 0 # l'indice de la première couche de l'encodeur (input)
output_layer_index = 9 # l'indice de la dernière couche (la sortie) de l'encodeur (dépend de votre architecture)
# note: Pour identifier l'indice de la dernière couche de la partie encodeur, vous pouvez utiliser la fonction "model.summary()"
# chaque ligne dans le tableau affiché par "model.summary" est compté comme une couche
encoder = Model(autoencoder.layers[input_layer_index].input, autoencoder.layers[output_layer_index].output)

encoder.summary()

encoded_data = encoder.predict(x)
print(encoded_data.shape)
embedding= encoded_data.flatten().reshape(400, 25088)
embedding.shape

# ***********************************************
#                  QUESTIONS
# ***********************************************
#
# 4) Normaliser le flattened embedding (les vecteurs recupérés dans question 3)
# en utilisant le StandardScaler
# ***********************************************
scaler = StandardScaler()

embedding = scaler.fit_transform(embedding)

# ***********************************************
#                  QUESTIONS
# ***********************************************
#
# 5) Appliquer un SVM Linéaire sur les images originales (avant l'encodage par le modèle)
# Entrainer le modèle avec le cross-validation
# Afficher la métrique suivante :
#    - Accuracy
# ***********************************************
x_train = x.reshape(400, 37632)
x_train = x_train.astype('float32')
x_train /= 255
print(x_train.shape[0], 'train samples')
clf_svm_original = LinearSVC()

scores_original = cross_val_score(clf_svm_original, x_train, y_true)
print(scores_original)
print("%0.2f accuracy" % (scores_original.mean()))

# ***********************************************
#                  QUESTIONS
# ***********************************************
#
# 6) Appliquer un SVC Linéaire sur le flattened embedding normalisé
# Entrainer le modèle avec le cross-validation
# Afficher la métrique suivante :
#    - Accuracy
# ***********************************************
clf_svm = LinearSVC()

scores = cross_val_score(clf_svm, embedding, y_true)
print(scores)
print("%0.2f accuracy " % (scores.mean()))

# ***********************************************
#                  QUESTIONS
# ***********************************************
#
# 7) Appliquer TSNE sur le flattened embedding afin de réduire sa dimensionnalité en 2 dimensions
# Puis afficher les 2D features dans un scatter plot en utilisant 2 couleurs(une couleur par classe)
# ***********************************************
# Reduction de la dimension
enb_reduce = TSNE(n_components=2).fit_transform(embedding)
# affichage de la figure

plt.figure(figsize=(8,8))
plt.scatter(enb_reduce[:, 0], enb_reduce[:, 1], c=y_true, cmap='brg')
plt.colorbar()
plt.show()